# Alternatives to GPD: Other Approaches to Human-AI Accountability

**A companion resource to the Generative Productive Dialogue (GPD) Framework**

**Date:** December 6, 2025  
**Version:** 1.0  
**Related:** [GPD Framework v1.1](https://gist.github.com/ivarada/599db1f525875d952562187f8663bec9)

---

## Overview

GPD is practitioner vocabulary — a lens for reasoning, not a rule to follow. But it exists alongside other approaches to human-AI accountability. This document provides verified links to the major alternatives, their mechanisms, and their limitations.

The key distinction: **GPD is an internal practice. The others are external controls. Both are needed.**

---

## The Landscape

| Approach | Mechanism | Limitation |
| :---- | :---- | :---- |
| **Disclosure Mandates** | Legal requirement to label AI content | Compliance-driven, not internalized |
| **Watermarking/Detection** | Technical fingerprinting of AI output | Arms race; already being defeated |
| **Professional Licensing Rules** | Bar associations and medical boards regulate the use | Domain-specific; patchwork coverage |
| **Prohibition** | Ban AI in specific contexts (exams, courts) | Unenforceable at scale |
| **Liability Frameworks** | Legal accountability for AI-assisted harm | Reactive, not preventive |
| **AI Literacy Education** | Teach people how AI works | Slow; doesn't change incentives |
| **Tool Design Friction** | Verification prompts, speed bumps | Can be clicked through mindlessly |

---

## 1\. Disclosure Mandates (EU AI Act)

**Mechanism:** Legal requirement to label AI-generated content  
**Limitation:** Compliance-driven, not internalized  
**Effective:** August 2, 2026 (transparency provisions)

### Key Requirements

- AI systems interacting with users must disclose that they are AI systems  
- AI-generated content (text, images, audio, video) must be marked as artificially generated  
- Deep fakes require explicit disclosure  
- Penalties up to €35 million or 7% of global annual turnover

### Sources

- **EU AI Act Article 50** (transparency obligations)  
  [https://artificialintelligenceact.eu/article/50/](https://artificialintelligenceact.eu/article/50/)  
    
- **EU Digital Strategy Overview**  
  [https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)  
    
- **White & Case Legal Analysis**  
  [https://www.whitecase.com/insight-alert/long-awaited-eu-ai-act-becomes-law-after-publication-eus-official-journal](https://www.whitecase.com/insight-alert/long-awaited-eu-ai-act-becomes-law-after-publication-eus-official-journal)  
    
- **European Parliament Summary**  
  [https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence](https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence)

---

## 2\. Watermarking/Detection

**Mechanism:** Technical fingerprinting embedded in AI output  
**Limitation:** Arms race; already being defeated  
**Status:** Active development, limited effectiveness

### Key Findings

- Screenshot defeats most metadata-based watermarks  
- Text watermarks can be removed with a \~85% success rate through rewording  
- Open-source models don't produce watermarks at all  
- False favorable rates up to 15-20% for text detection

### Sources

- **EFF Analysis** — "AI Watermarking Won't Curb Disinformation"  
  [https://www.eff.org/deeplinks/2024/01/ai-watermarking-wont-curb-disinformation](https://www.eff.org/deeplinks/2024/01/ai-watermarking-wont-curb-disinformation)  
    
- **Brookings Institution** — "Detecting AI Fingerprints: A Guide to Watermarking and Beyond"  
  [https://www.brookings.edu/articles/detecting-ai-fingerprints-a-guide-to-watermarking-and-beyond/](https://www.brookings.edu/articles/detecting-ai-fingerprints-a-guide-to-watermarking-and-beyond/)  
    
- **IEEE Spectrum** — "Meta's AI Watermarking Plan Is Flimsy, at Best"  
  [https://spectrum.ieee.org/meta-ai-watermarks](https://spectrum.ieee.org/meta-ai-watermarks)  
    
- **International AI Safety Report 2025**  
  [https://internationalaisafetyreport.org/publication/international-ai-safety-report-2025](https://internationalaisafetyreport.org/publication/international-ai-safety-report-2025)  
    
  "Technical countermeasures like content watermarking, although useful, can usually be circumvented by moderately sophisticated actors."  
    
- **arXiv Research** — "Missing the Mark: Adoption of Watermarking for Generative AI System."  
  [https://arxiv.org/html/2503.18156v3](https://arxiv.org/html/2503.18156v3)  
    
  Found only 38% of AI image generators implement adequate watermarking; 18% implement deep fake labeling

---

## 3\. Professional Licensing Rules

**Mechanism:** Bar associations and medical boards regulate AI use by licensed professionals  
**Limitation:** Domain-specific; patchwork coverage across jurisdictions  
**Status:** Rapidly evolving (2024-2025)

### Legal Profession

- **ABA Formal Opinion 512** (July 2024\) — First comprehensive ethics guidance  
  [https://www.americanbar.org/news/abanews/aba-news-archives/2024/07/aba-issues-first-ethics-guidance-ai-tools/](https://www.americanbar.org/news/abanews/aba-news-archives/2024/07/aba-issues-first-ethics-guidance-ai-tools/)  
    
- **Justia 50-State Survey** — AI and Attorney Ethics Rules  
  [https://www.justia.com/trials-litigation/ai-and-attorney-ethics-rules-50-state-survey/](https://www.justia.com/trials-litigation/ai-and-attorney-ethics-rules-50-state-survey/)  
    
- **Debevoise Analysis** — ABA Guidelines breakdown  
  [https://www.debevoisedatablog.com/2024/08/05/guidelines-on-the-use-of-generative-ai-tools-by-professionals-from-the-american-bar-association/](https://www.debevoisedatablog.com/2024/08/05/guidelines-on-the-use-of-generative-ai-tools-by-professionals-from-the-american-bar-association/)

### Medical Profession

- **FSMB Guidelines** (May 2024\) — Federation of State Medical Boards  
  [https://www.fsmb.org/advocacy/news-releases/fsmb-releases-recommendations-on-the-responsible-and-ethical-incorporation-of-ai-into-clinical-practice/](https://www.fsmb.org/advocacy/news-releases/fsmb-releases-recommendations-on-the-responsible-and-ethical-incorporation-of-ai-into-clinical-practice/)  
    
- **Full FSMB Report** (PDF)  
  [https://www.fsmb.org/siteassets/advocacy/policies/incorporation-of-ai-into-practice.pdf](https://www.fsmb.org/siteassets/advocacy/policies/incorporation-of-ai-into-practice.pdf)  
    
- **AMA Overview** — States stepping up on health AI regulation  
  [https://www.ama-assn.org/practice-management/digital-health/states-are-stepping-health-ai-regulation](https://www.ama-assn.org/practice-management/digital-health/states-are-stepping-health-ai-regulation)  
    
- **California AB 3030** — Patient consent required for AI in care  
  [https://www.hklaw.com/en/insights/publications/2024/10/regulation-of-ai-in-healthcare-utilization-management](https://www.hklaw.com/en/insights/publications/2024/10/regulation-of-ai-in-healthcare-utilization-management)

---

## 4\. Prohibition

**Mechanism:** Ban AI use in specific contexts (academic exams, court filings)  
**Limitation:** Unenforceable at scale  
**Status:** Shifting from bans toward disclosure requirements

### Academic Context

- **Fortune** — "ChatGPT bans evolve into 'AI literacy'"  
  [https://fortune.com/2025/09/12/college-cheating-ai-literacy-bans-exams-homework/](https://fortune.com/2025/09/12/college-cheating-ai-literacy-bans-exams-homework/)  
    
  "The cheating is off the charts. It's the worst I've seen in my entire career."  
    
- **HEPI 2025 Survey** — 88% of UK students used AI for assessments (up from 53% previous year)  
    
- **Freedom for All Americans** — Comprehensive overview of higher education AI policies  
  [https://freedomforallamericans.org/chatgpt-education-debate/](https://freedomforallamericans.org/chatgpt-education-debate/)

### Legal Context

- **Charlotte Federal Court Ban** (June 2024\)  
  [https://charlotteledger.substack.com/p/charlottes-federal-judges-ban-use](https://charlotteledger.substack.com/p/charlottes-federal-judges-ban-use)  
    
- **Texas Judge Ban Order** (June 2023\)  
  [https://www.cbsnews.com/news/texas-judge-bans-chatgpt-court-filing/](https://www.cbsnews.com/news/texas-judge-bans-chatgpt-court-filing/)  
    
- **Sanctions for ChatGPT Hallucinations** — $5,000 fine, Mata v. Avianca  
  [https://www.courthousenews.com/sanctions-ordered-for-lawyers-who-relied-on-chatgpt-artificial-intelligence-to-prepare-court-brief/](https://www.courthousenews.com/sanctions-ordered-for-lawyers-who-relied-on-chatgpt-artificial-intelligence-to-prepare-court-brief/)  
    
- **Cronkite News** — AI Hallucination Cases database: 486 cases worldwide, 324 in U.S. courts  
  [https://cronkitenews.azpbs.org/2025/10/28/lawyers-ai-hallucinations-chatgpt/](https://cronkitenews.azpbs.org/2025/10/28/lawyers-ai-hallucinations-chatgpt/)  
    
- **ABA Business Law Today** — Common issues in AI sanction jurisprudence  
  [https://businesslawtoday.org/2024/09/common-issues-ai-sanction-jurisprudence-how-federal-judiciary-has-responded-to-prevent-them/](https://businesslawtoday.org/2024/09/common-issues-ai-sanction-jurisprudence-how-federal-judiciary-has-responded-to-prevent-them/)

---

## 5\. Liability Frameworks

**Mechanism:** Legal accountability for AI-assisted harm  
**Limitation:** Reactive, not preventive; unclear responsibility chains  
**Status:** Evolving; EU directive withdrawn February 2025

### Key Challenges

- Determining liability when AI is involved in decision-making (provider vs. developer vs. institution)  
- "Black box" nature makes accountability difficult  
- Traditional tort law is not designed for AI-caused harms  
- Proximate cause is harder to establish with unpredictable AI behavior

### Sources

- **NTIA AI Accountability Policy Report** — Liability rules and standards  
  [https://www.ntia.gov/issues/artificial-intelligence/ai-accountability-policy-report/using-accountability-inputs/liability-rules-and-standards](https://www.ntia.gov/issues/artificial-intelligence/ai-accountability-policy-report/using-accountability-inputs/liability-rules-and-standards)  
    
- **RAND Corporation** — "Liability for Harms from AI Systems."  
  [https://www.rand.org/pubs/research\_reports/RRA3243-4.html](https://www.rand.org/pubs/research_reports/RRA3243-4.html)  
    
- **EU AI Liability Directive** — Proposed September 2022, withdrawn February 2025  
  [https://www.ai-liability-directive.com/](https://www.ai-liability-directive.com/)  
    
- **Royal Society Open Science** — Healthcare AI ethical and legal considerations  
  [https://royalsocietypublishing.org/doi/10.1098/rsos.241873](https://royalsocietypublishing.org/doi/10.1098/rsos.241873)  
    
- **Carnegie Endowment** — California SB-53 frontier AI law (October 2025\)  
  [https://carnegieendowment.org/emissary/2025/10/california-sb-53-frontier-ai-law-what-it-does](https://carnegieendowment.org/emissary/2025/10/california-sb-53-frontier-ai-law-what-it-does)  
    
- **AI Frontiers** — "The Case for AI Liability."  
  [https://ai-frontiers.org/articles/case-for-ai-liability](https://ai-frontiers.org/articles/case-for-ai-liability)

---

## 6\. AI Literacy Education

**Mechanism:** Teach people how AI works, its capabilities, and limitations  
**Limitation:** Slow to scale; doesn't change incentives  
**Status:** Growing but fragmented

### Key Frameworks

- Technical understanding of how AI works  
- Evaluative skills for critically assessing AI outputs  
- Practical application in professional contexts  
- Ethical considerations and bias awareness

### Sources

- **EDUCAUSE AI Literacy Framework** (October 2024\)  
  [https://www.educause.edu/content/2024/ai-literacy-in-teaching-and-learning/executive-summary](https://www.educause.edu/content/2024/ai-literacy-in-teaching-and-learning/executive-summary)  
    
- **Stanford Teaching Commons** — Understanding AI Literacy  
  [https://teachingcommons.stanford.edu/teaching-guides/artificial-intelligence-teaching-guide/understanding-ai-literacy](https://teachingcommons.stanford.edu/teaching-guides/artificial-intelligence-teaching-guide/understanding-ai-literacy)  
    
- **Nature Humanities & Social Sciences** — Decade of AI literacy research (2014-2024)  
  [https://www.nature.com/articles/s41599-025-04583-8](https://www.nature.com/articles/s41599-025-04583-8)  
    
- **EdWeek** — "It's Not Magic: How These Schools Are Teaching AI Literacy."  
  [https://www.edweek.org/technology/its-not-magic-how-these-schools-are-teaching-ai-literacy/2025/10](https://www.edweek.org/technology/its-not-magic-how-these-schools-are-teaching-ai-literacy/2025/10)  
    
- **Federation of American Scientists** — Teacher AI Literacy Development Program proposal  
  [https://fas.org/publication/teacher-ai-literacy-development/](https://fas.org/publication/teacher-ai-literacy-development/)

### Critical Perspective

"Very little \[time\] is actually spent on saying, 'And therefore, you shouldn't use it.'" — Benjamin Riley, Cognitive Resonance

---

## 7\. Tool Design Friction

**Mechanism:** Verification prompts, confirmation dialogs, speed bumps in AI interfaces  
**Limitation:** Can be clicked through mindlessly; habituation reduces effectiveness  
**Status:** Emerging research area

### Key Insight

"How easy something is to achieve should be inversely proportional to its importance."

### Sources

- **Mozilla Foundation** — "The Importance of Friction in AI Systems"  
  [https://www.mozillafoundation.org/en/blog/the-importance-of-friction-in-ai-systems/](https://www.mozillafoundation.org/en/blog/the-importance-of-friction-in-ai-systems/)  
    
- **Envy Labs** — "How to Use Interface Design Friction to Your Advantage"  
  [https://envylabs.com/insights/breaking-down-good-and-bad-interface-design-friction](https://envylabs.com/insights/breaking-down-good-and-bad-interface-design-friction)  
    
- **ACM ECCE Proceedings** — Design Friction research  
  [https://dl.acm.org/doi/10.1145/3335082.3335106](https://dl.acm.org/doi/10.1145/3335082.3335106)  
    
- **Medium/Bootcamp** — "Designing for Human Agency Through Intentional Friction"  
  [https://medium.com/design-bootcamp/designing-for-human-agency-through-intentional-friction-9baba36467ed](https://medium.com/design-bootcamp/designing-for-human-agency-through-intentional-friction-9baba36467ed)

---

## Why GPD Differs

All seven approaches above are **external controls** — regulations, technologies, or institutional policies applied from outside the practitioner.

GPD is an **internal practice** — vocabulary and a framework that helps individuals reason about their own AI use.

| External Controls | Internal Practice (GPD) |
| :---- | :---- |
| Compliance-driven | Values-driven |
| Imposed by institutions | Adopted by practitioners |
| Requires enforcement | Self-reinforcing through vocabulary |
| Reactive to violations | Proactive through awareness |
| Domain-specific | Cross-domain applicable |

**Both are needed.** External controls set boundaries. Internal practice develops judgment.

---

## How to Use This Resource

1. **For policy work:** Reference specific sources when discussing the regulatory landscape.  
2. **For GPD adoption:** Understand where GPD sits relative to other approaches  
3. **For research:** Use as a starting point for literature on AI accountability mechanisms  
4. **For teaching:** Illustrate the full spectrum of human-AI accountability approaches

